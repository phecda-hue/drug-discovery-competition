{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Machine Lerning-based Drug Discovery Pipeline\n",
        "\n",
        "This notebook presents an end-to-end pipeline for predicting molecular inhibition using multiple molecular representations and machine learning models.\n",
        "\n",
        "The workflow includes:\n",
        "1. Data preprocessing\n",
        "2. Molecular feature extraction\n",
        "3. Model training and hyperparameter optimization\n",
        "4. Ensemble learning\n",
        "5. Predictions and submission file generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup and Library Import\n",
        "\n",
        "This section installs and imports all required libraries for molecular processing, graph neural networks, classical machine learning models, and feature extraction.\n",
        "\n",
        "Key libraries:\n",
        "- RDKit for molecular representation\n",
        "- PyTorch Geometric for graph-based learning\n",
        "- Scikit-learn, XGBoost, LightBGM, CatBoost for regression models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install rdkit\n",
        "!pip install torch_geometric\n",
        "!pip install catboost\n",
        "!pip install mordred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTnO4F0mZWOE",
        "outputId": "a5b631e3-2d81-4941-966b-d9de7783588d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors, AllChem, MACCSkeys, Descriptors3D, QED\n",
        "from rdkit.DataStructs.cDataStructs import ConvertToNumpyArray\n",
        "from torch_geometric.data import Data\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.data import Batch\n",
        "from sklearn.ensemble import RandomForestRegressor, StackingRegressor, HistGradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from mordred import Calculator, descriptors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Loading and Preprocessing\n",
        "\n",
        "Training and test datasets are loaded and cleaned.\n",
        "Only valid SMILES strings and target values are retained to ensure reliable feature extractions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OtdJU75YmD5h"
      },
      "outputs": [],
      "source": [
        "# 데이터 불러오기\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "train = train[['Canonical_Smiles', 'Inhibition']]\n",
        "train = train.dropna()\n",
        "\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "test = test.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Molecular Graph Construction\n",
        "\n",
        "SMILES strings are converted into graph representations where atoms are nodes and bonds are edges.\n",
        "This enables graph-based deep learning models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mol_to_graph(mol):\n",
        "  node_feats = []\n",
        "  edge_index = []\n",
        "\n",
        "  for atom in mol.GetAtoms():\n",
        "    node_feats.append([atom.GetAtomicNum()])\n",
        "\n",
        "  for bond in mol.GetBonds():\n",
        "    i = bond.GetBeginAtomIdx()\n",
        "    j = bond.GetEndAtomIdx()\n",
        "    edge_index.append((i, j))\n",
        "    edge_index.append((j, i))\n",
        "\n",
        "  x = torch.tensor(node_feats, dtype=torch.float)\n",
        "  edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "\n",
        "  data = Data(x=x, edge_index=edge_index)\n",
        "  data.num_nodes = x.size(0)\n",
        "  data.batch = torch.zeros(x.size(0), dtype=torch.long)\n",
        "\n",
        "  return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Graph Neural Network Architecture\n",
        "\n",
        "A Graph Convolutional Network(GCN) is defiened to learn latent representations of molecules from graph-structed data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GCN(torch.nn.Module):\n",
        "  def __init__(self, input_dim=1, hidden_dim=64, output_dim=1):\n",
        "    super().__init__()\n",
        "    self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "    self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
        "    self.lin = torch.nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "  def forward(self, data):\n",
        "    x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "    x = F.relu(self.conv1(x, edge_index))\n",
        "    x = F.relu(self.conv2(x, edge_index))\n",
        "    x = global_mean_pool(x, batch)\n",
        "    return self.lin(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training the GNN model\n",
        "\n",
        "The GNN is trained to predict inhibition values using molecular graph representations.\n",
        "The trained model is later used as a feature extractor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = GCN()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "graph_data_list = []\n",
        "for idx, row in train.iterrows():\n",
        "  mol = Chem.MolFromSmiles(row['Canonical_Smiles'])\n",
        "  if mol:\n",
        "    data = mol_to_graph(mol)\n",
        "    data.y = torch.tensor([row['Inhibition']], dtype=torch.float)\n",
        "    graph_data_list.append(data)\n",
        "\n",
        "train_loader = DataLoader(graph_data_list, batch_size=32, shuffle=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "for epoch in range(200):\n",
        "  for data in train_loader:\n",
        "    data = data.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = F.mse_loss(out.squeeze(), data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. GNN-based Latent Feature Extraction\n",
        "\n",
        "Latent molecular representations are extracted from the trained GNN and used as additional features for classical machine learning models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_gnn_latent(smiles):\n",
        "  mol = Chem.MolFromSmiles(smiles)\n",
        "  if mol is None:\n",
        "    return [0.0] * 1\n",
        "  data = mol_to_graph(mol)\n",
        "  data.y = torch.tensor([0.0])\n",
        "  batch = Batch.from_data_list([data]).to(device)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    out = model(batch)\n",
        "  return out.view(-1).cpu().tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Classical Molecular Feature Extraction\n",
        "\n",
        "This section computes physicochemical descriptors, fingerprints, graph-based statistics, and 3D descriptors for classical ML models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7-bmg3cnwdw"
      },
      "outputs": [],
      "source": [
        "def compute_3d_descriptors(smiles):\n",
        "  mol = Chem.MolFromSmiles(smiles)\n",
        "  mol = Chem.AddHs(mol)\n",
        "  success = AllChem.EmbedMolecule(mol, AllChem.ETKDG())\n",
        "  if success != 0:\n",
        "    return None\n",
        "  AllChem.UFFOptimizeMolecule(mol)\n",
        "  descriptors = {'Asphericity': Descriptors3D.Asphericity(mol), 'Eccentricity': Descriptors3D.Eccentricity(mol), 'InertialShapeFactor': Descriptors3D.InertialShapeFactor(mol), 'SpherocityIndex': Descriptors3D.SpherocityIndex(mol)}\n",
        "  return descriptors\n",
        "\n",
        "def compute_graph_features(mol):\n",
        "  num_atoms = mol.GetNumAtoms()\n",
        "  num_bonds = mol.GetNumBonds()\n",
        "  ring_info = mol.GetRingInfo()\n",
        "  num_rings = ring_info.NumRings()\n",
        "  distance_matrix = Chem.GetDistanceMatrix(mol)\n",
        "  diameter = distance_matrix.max()\n",
        "  return {'NumAtoms': num_atoms, 'NumBonds': num_bonds, 'NumRings': num_rings, 'GraphDiameter': diameter}\n",
        "\n",
        "calc = Calculator([descriptors.BertzCT])\n",
        "\n",
        "def extract_features(smiles):\n",
        "  mol = Chem.MolFromSmiles(smiles)\n",
        "  if mol is None:\n",
        "    print(f\"Invalid SMILES: {smiles}\")\n",
        "    return None\n",
        "  try:\n",
        "      features = [\n",
        "        Descriptors.MolWt(mol),\n",
        "        Descriptors.MolLogP(mol),\n",
        "        Descriptors.NumHAcceptors(mol),\n",
        "        Descriptors.NumHDonors(mol),\n",
        "        Descriptors.TPSA(mol),\n",
        "        Descriptors.NumRotatableBonds(mol),\n",
        "        Descriptors.FractionCSP3(mol),\n",
        "        Descriptors.HeavyAtomCount(mol),\n",
        "        Descriptors.NHOHCount(mol),\n",
        "        Descriptors.NOCount(mol),\n",
        "        Descriptors.NumAromaticRings(mol),\n",
        "        Descriptors.NumSaturatedRings(mol),\n",
        "        Descriptors.NumAliphaticRings(mol),\n",
        "        Descriptors.NumAromaticCarbocycles(mol),\n",
        "        Descriptors.NumValenceElectrons(mol),\n",
        "        Descriptors.MolMR(mol),\n",
        "        Descriptors.HallKierAlpha(mol),\n",
        "        Descriptors.LabuteASA(mol)\n",
        "        ]\n",
        "      fp_morgan = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=4096, useFeatures=True, useChirality=True)\n",
        "      fp_morgan_bits = list(fp_morgan)\n",
        "      arr_morgan = np.zeros((4096,), dtype=int)\n",
        "      ConvertToNumpyArray(fp_morgan, arr_morgan)\n",
        "      fp_morgan_bits = arr_morgan.tolist()\n",
        "\n",
        "      fp_maccs = MACCSkeys.GenMACCSKeys(mol)\n",
        "      arr_maccs = np.zeros((167, ), dtype=int)\n",
        "      ConvertToNumpyArray(fp_maccs, arr_maccs)\n",
        "      fp_maccs_bits = arr_maccs.tolist()\n",
        "\n",
        "      graph_feats = compute_graph_features(mol)\n",
        "      graph_feats_list = list(graph_feats.values())\n",
        "\n",
        "      desc3d = compute_3d_descriptors(smiles)\n",
        "      if desc3d is None:\n",
        "        print(f\"Failed to compute 3D descriptors for {smiles}\")\n",
        "        desc3d_list = [0.0] * 4\n",
        "      else:\n",
        "        desc3d_list = list(desc3d.values())\n",
        "\n",
        "      gnn_latent = get_gnn_latent(smiles)\n",
        "\n",
        "      qed_value = QED.qed(mol)\n",
        "\n",
        "      res = calc(mol)\n",
        "      bertz = res['BertzCT']\n",
        "\n",
        "      return features + fp_morgan_bits + fp_maccs_bits + graph_feats_list + desc3d_list + gnn_latent + [qed_value, bertz]\n",
        "  except Exception as e:\n",
        "    print(f\"Error processing {smiles}: {e}\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Feature Matrix Construction\n",
        "\n",
        "Multiple molecular features are extracted and combined into tabular datasets for classical machine learning models.\n",
        "Invalid molecules are excluded during this process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75lAix4ny8CX",
        "outputId": "0637b869-b29a-4000-8707-81b80c1572ab"
      },
      "outputs": [],
      "source": [
        "# 훈련, 테스트 데이터 생성\n",
        "X_train_list = []\n",
        "Y_train_list = []\n",
        "\n",
        "for smiles, y, in zip(train[\"Canonical_Smiles\"], train[\"Inhibition\"]):\n",
        "  feats = extract_features(smiles)\n",
        "  if feats is not None:\n",
        "    X_train_list.append(feats)\n",
        "    Y_train_list.append(y)\n",
        "\n",
        "X_train = pd.DataFrame(X_train_list)\n",
        "Y_train = pd.Series(Y_train_list, index=X_train.index).astype(float)\n",
        "\n",
        "X_test_list = []\n",
        "test_ids = []\n",
        "for smiles, idx in zip(test[\"Canonical_Smiles\"], test[\"ID\"]):\n",
        "  feats = extract_features(smiles)\n",
        "  if feats is not None:\n",
        "    X_test_list.append(feats)\n",
        "    test_ids.append(idx)\n",
        "\n",
        "X_test = pd.DataFrame(X_test_list)\n",
        "\n",
        "all_features = X_train.columns.tolist()\n",
        "features_without_bertz = [f for f in X_train.columns if f != 'BertzCT']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Model Training and Hyperparameter Optimization\n",
        "\n",
        "Multiple regression models are trained using different feature subsets.\n",
        "Model-specific feature selection is applied based on empirical performance differences observed during experimentation.\n",
        "\n",
        "Different models benefited from different feature representations, highliting the importance of model-feature compatibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gW51tDhy_eFL",
        "outputId": "727cdb6b-87f7-4c84-83a5-fc9d5d63f925"
      },
      "outputs": [],
      "source": [
        "# 모델 생성 및 적합\n",
        "xgb_param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [5, 6, 7],\n",
        "    'learning_rate': [0.03, 0.05, 0.07],\n",
        "    'subsample': [0.7, 0.9, 1.0]\n",
        "}\n",
        "xgb_search = RandomizedSearchCV(XGBRegressor(tree_method='hist'), param_distributions=xgb_param_grid, n_iter=30, scoring='neg_mean_squared_error', cv=3, n_jobs=-1)\n",
        "xgb_search.fit(X_train[features_without_bertz], Y_train)\n",
        "best_xgb = xgb_search.best_estimator_\n",
        "\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [15, 20, 25],\n",
        "    'min_samples_leaf': [5, 10, 15]\n",
        "}\n",
        "rf_search = RandomizedSearchCV(RandomForestRegressor(), param_distributions=rf_param_grid, n_iter=30, scoring='neg_mean_squared_error', cv=3, n_jobs=-1)\n",
        "rf_search.fit(X_train[features_without_bertz], Y_train)\n",
        "best_rf = rf_search.best_estimator_\n",
        "\n",
        "lgbm_param_grid = {\n",
        "    'learning_rate': [0.03, 0.05, 0.07, 0.1],\n",
        "    'max_depth': [7, 15, 31],\n",
        "    'lambda_l1': [10, 20, 30],\n",
        "    'lambda_l2': [10, 20, 30],\n",
        "    'num_leaves': [20, 30, 40],\n",
        "    'min_child_samples': [10, 20]\n",
        "}\n",
        "lgbm_search = RandomizedSearchCV(LGBMRegressor(), param_distributions=lgbm_param_grid, n_iter=30, scoring='neg_mean_squared_error', cv=3, n_jobs=-1)\n",
        "lgbm_search.fit(X_train[all_features], Y_train)\n",
        "best_lgbm = lgbm_search.best_estimator_\n",
        "\n",
        "cat_param_grid = {\n",
        "    'learning_rate': [0.03, 0.05, 0.07],\n",
        "    'depth': [2, 4, 6],\n",
        "    'l2_leaf_reg': [5, 7, 10],\n",
        "    'iterations': [200, 400, 600]\n",
        "}\n",
        "cat_search = RandomizedSearchCV(CatBoostRegressor(verbose=0, task_type=\"CPU\"), param_distributions=cat_param_grid, n_iter=30, scoring='neg_mean_squared_error', cv=3, n_jobs=-1)\n",
        "cat_search.fit(X_train[features_without_bertz], Y_train)\n",
        "best_cat = cat_search.best_estimator_\n",
        "\n",
        "gradient_param_grid = {\n",
        "    'max_iter': [300, 400, 500],\n",
        "    'learning_rate': [0.03, 0.05, 0.07],\n",
        "    'max_leaf_nodes': [5, 7, 10]\n",
        "}\n",
        "gradient_search = RandomizedSearchCV(HistGradientBoostingRegressor(early_stopping=True), param_distributions=gradient_param_grid, n_iter=27, scoring='neg_mean_squared_error', cv=3, n_jobs=-1)\n",
        "gradient_search.fit(X_train[features_without_bertz], Y_train)\n",
        "best_gradient = gradient_search.best_estimator_\n",
        "\n",
        "stacking = StackingRegressor(estimators=[('xgb', best_xgb), ('rf', best_rf), ('cat', best_cat), ('lgbm', best_lgbm)], final_estimator=best_gradient, cv=5, passthrough=False, n_jobs=-1)\n",
        "\n",
        "stacking.fit(X_train[all_features], Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Model Evaluation\n",
        "\n",
        "The ensemble model is evaluated on the training data using normalized RNSE and Pearson correlation, following the competition evaluation criteria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuRj27UbI9hP",
        "outputId": "df2ee1ad-6653-4733-f8c3-d8666f53e9ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
            "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
            "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
            "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
            "Normalized RMSE: 0.1938\n",
            "Pearson Correlation: 0.7500\n",
            "Final Score: 0.778092\n"
          ]
        }
      ],
      "source": [
        "# 예측 및 평가\n",
        "Y_pred_train = stacking.predict(X_train)\n",
        "Y_pred_test = stacking.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(Y_train, Y_pred_train))\n",
        "norm_rmse = rmse / (max(Y_train) - min(Y_train))\n",
        "corr, _ = pearsonr(Y_train, Y_pred_train)\n",
        "score = 0.5 * (1- min(norm_rmse, 1)) + 0.5 * corr\n",
        "\n",
        "print(f\"Normalized RMSE: {norm_rmse:.4f}\")\n",
        "print(f\"Pearson Correlation: {corr:.4f}\")\n",
        "print(f\"Final Score: {score:4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Submission File Generation\n",
        "\n",
        "Final predictions on the test dataset are generated and saved in the required submission format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0X2NnzlhNmgg"
      },
      "outputs": [],
      "source": [
        "# 파일 작성\n",
        "submission = pd.DataFrame({\"ID\": test_ids, \"Inhibition\": Y_pred_test})\n",
        "submission.to_csv(\"submission_250729_1.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
